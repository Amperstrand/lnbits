name: Test2 JMeter Action

on:
  workflow_call:
    inputs:
      python-version:
        description: "Python Version"
        required: true
        default: "3.9"
      poetry-version:
        description: "Poetry Version"
        default: "1.5.1"

jobs:
  action_build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Set up Python ${{ inputs.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python-version }}
          # cache poetry install via pip
          cache: "pip"

      - name: Set up Poetry ${{ inputs.poetry-version }}
        uses: abatilo/actions-poetry@v2
        with:
          poetry-version: ${{ inputs.poetry-version }}

      - name: create reports dir
        run: poetry run lnbits

      - name: create reports dir
        run: mkdir reports

      - name: install jmeter
        run: |
          java -version
          wget https://downloads.apache.org//jmeter/binaries/apache-jmeter-5.5.zip
          unzip apache-jmeter-5.5.zip
          cd apache-jmeter-5.5/bin
          ./jmeter -v
          pwd

      - name: run jmx scripts
        run: |
          for file in $( ls $GITHUB_WORKSPACE/integration/*.jmx); do
            echo "Running test with $file"
            filename=$(basename "$file" ".jmx")
            $GITHUB_WORKSPACE/apache-jmeter-5.5/bin/jmeter -n -t $file -l logs/$filename.log -e -o reports;
            error_count=$(cat jmeter.log | grep "summary =" | awk '{print $19}')
            echo "Error count: $error_count"
            if [ "$error_count" != "0" ]
            then
              echo "Test $filename failed. Error count: $error_count."
              cat logs/$filename.log
              exit 1
            else
              echo "Test $filename OK."
            fi
          done

      - uses: actions/upload-artifact@v1
        if: ${{ always() }}
        with:
          name: jmeter-test-results
          path: reports/
